{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f code_for_hw02.py*\n",
    "!wget --no-check-certificate --quiet https://introml_oll.odl.mit.edu/6.036/static/homework/hw02/code_for_hw02.py\n",
    "from code_for_hw02 import *\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron algorithm\n",
    "\n",
    "Implement [the perceptron algorithm](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2019_Spring/courseware/Week2/perceptron/2), where\n",
    "\n",
    "* `data` is a numpy array ($d$ by $n$)\n",
    "* `labels` is numpy array ($1$ by $n$)\n",
    "* `params` is a dictionary. Availiable paramaters: iterations $T$\n",
    "* `hook` unused.\n",
    "\n",
    "It should return a tuple of $\\theta$ (a $d$ by 1 array) and $\\theta_0$ (a 1 by 1 array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = np.array([[0]] * d)\n",
    "    th0 = np.array([[0]])\n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "        \n",
    "        # axes = tidy_plot(-50, 50, -50, 50)\n",
    "        # print(th)\n",
    "        # print(th0)\n",
    "        # plot_data(data, labels, axes)\n",
    "        # plot_separator(axes, th, th0)\n",
    "    return (th, th0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perceptron(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = ths = np.array([[0]] * d)\n",
    "    th0 = th0s = np.array([[0]])\n",
    "    \n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "            ths = ths + th\n",
    "            th0s = th0s + th0\n",
    "    return (ths / n / T, th0s / n / T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Test Failed.\n",
      "Your code output  th: [[-9.0525], [17.5825]], th0: [[0.0]]\n",
      "Expected  th: [[-9.0], [18.0]], th0: [[2.0]]\n",
      "\n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Test Failed.\n",
      "Your code output  th: [[1.47], [-1.7275]], th0: [[0.0]]\n",
      "Expected  th: [[0.0], [-3.0]], th0: [[0.0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perceptron(averaged_perceptron) # should be wrong but close to the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "\n",
    "    n = len(data_test[0])\n",
    "    cnt = 0\n",
    "    for i in range(n):\n",
    "        x = np.array([data_test[:,i]])\n",
    "        y = labels_test[:,i]\n",
    "\n",
    "        if np.sign(np.dot(x, th) + th0) == y:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Classifier 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Classifier 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_classifier(eval_classifier, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    perf = 0\n",
    "    for iter in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "        perf = perf + eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    perf /= it\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_learning_alg(eval_learning_alg, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    d = len(data)\n",
    "    data_chunk = np.array_split(data, k, axis=1)\n",
    "    lables_chunk = np.array_split(labels, k, axis=1)\n",
    "    perf = 0\n",
    "    for i in range(k):\n",
    "        data_train = np.array([[]] * d)\n",
    "        lables_train = np.array([[]])\n",
    "        for j in range(k):\n",
    "            if i != j:\n",
    "                data_train = np.concatenate((data_train, data_chunk[j]), axis=1)\n",
    "                lables_train = np.concatenate((lables_train, lables_chunk[j]), axis=1)\n",
    "        perf = perf + eval_classifier(learner, data_train, lables_train, data_chunk[i], lables_chunk[i])\n",
    "    return perf / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Cross-eval Learning Algo-----------\n",
      "Test Failed.\n",
      "Your code output  0.71\n",
      "Expected  0.61\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_xval_learning_alg(xval_learning_alg, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7754999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8188999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5924000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6522999999999998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_learning_alg(perceptron,           gen_flipped_lin_separable(pflip=0.1), 20, 100, 100))\n",
    "display(eval_learning_alg(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.1), 20, 100, 100))\n",
    "display(eval_learning_alg(perceptron,           gen_flipped_lin_separable(pflip=0.25), 20, 100, 100))\n",
    "display(eval_learning_alg(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.25), 20, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_training_acc(learner, data_gen, n_train, it):\n",
    "    perf = 0\n",
    "    for iter in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        perf = perf + eval_classifier(learner, data_train, labels_train, data_train, labels_train)\n",
    "    perf /= it\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8754999999999998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6725000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7345000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_training_acc(perceptron,           gen_flipped_lin_separable(pflip=0.1), 20, 100))\n",
    "display(eval_training_acc(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.1), 20, 100))\n",
    "display(eval_training_acc(perceptron,           gen_flipped_lin_separable(pflip=0.25), 20, 100))\n",
    "display(eval_training_acc(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.25), 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = np.array([[0]] * d)\n",
    "    th0 = np.array([[0]])\n",
    "\n",
    "    def decay_func(t):\n",
    "        return 0.5 - 0.4 * math.exp(-t)\n",
    "\n",
    "    for iter in range(T):\n",
    "        w = decay_func((iter + 1) / T)\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y * w\n",
    "                th = th + y * x.T * w\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "    return (th, th0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = ths = np.array([[0]] * d)\n",
    "    th0 = th0s = np.array([[0]])\n",
    "    sumw = 0\n",
    "    def reverse_decay_func(t):\n",
    "        return 0.5 + 0.4 * math.exp(-t)\n",
    "        \n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "            \n",
    "            t = (iter * n + i + 1) / T\n",
    "            w = reverse_decay_func(t)\n",
    "            ths = ths + th * w\n",
    "            th0s = th0s + th0 * w\n",
    "            sumw += w\n",
    "    return (ths / sumw, th0s / sumw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9964999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9984999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9984999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7494999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8545000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.777"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8809999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5479999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"learning accuracy: flip = 0\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.1\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.25\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.5\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
