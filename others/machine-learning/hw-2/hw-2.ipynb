{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing code_for_hw02\n",
      "New procedures added: tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv,\n",
      "                      rv, y, positive, score\n",
      "Data Sets: super_simple_separable_through_origin(), super_simple_separable(), xor(),\n",
      "           xor_more()\n",
      "Test data for problem 2.1: data1, labels1, data2, labels2\n",
      "Test data for problem 2.2: big_data, big_data_labels, gen_big_data(), gen_lin_separable(),\n",
      "                           big_higher_dim_separable(), gen_flipped_lin_separable()\n",
      "Test functions: test_linear_classifier(), test_perceptron(), test_averaged_perceptron(),\n",
      "                test_eval_classifier(), test_eval_learning_alg(), test_xval_learning_alg()\n",
      "\n",
      "For more information, use 'help', e.g. 'help tidy_plot'\n",
      "Done with import of code_for_hw02\n"
     ]
    }
   ],
   "source": [
    "!rm -f code_for_hw02.py*\n",
    "!wget --no-check-certificate --quiet https://introml_oll.odl.mit.edu/6.036/static/homework/hw02/code_for_hw02.py\n",
    "from code_for_hw02 import *\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron algorithm\n",
    "\n",
    "Implement [the perceptron algorithm](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2019_Spring/courseware/Week2/perceptron/2), where\n",
    "\n",
    "* `data` is a numpy array ($d$ by $n$)\n",
    "* `labels` is numpy array ($1$ by $n$)\n",
    "* `params` is a dictionary. Availiable paramaters: iterations $T$\n",
    "* `hook` unused.\n",
    "\n",
    "It should return a tuple of $\\theta$ (a $d$ by 1 array) and $\\theta_0$ (a 1 by 1 array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = np.array([[0]] * d)\n",
    "    th0 = np.array([[0]])\n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "        \n",
    "        # axes = tidy_plot(-50, 50, -50, 50)\n",
    "        # print(th)\n",
    "        # print(th0)\n",
    "        # plot_data(data, labels, axes)\n",
    "        # plot_separator(axes, th, th0)\n",
    "    return (th, th0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perceptron(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = ths = np.array([[0]] * d)\n",
    "    th0 = th0s = np.array([[0]])\n",
    "    \n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "            ths = ths + th\n",
    "            th0s = th0s + th0\n",
    "    return (ths / n / T, th0s / n / T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Perceptron 0-----------\n",
      "Test Failed.\n",
      "Your code output  th: [[-9.0525], [17.5825]], th0: [[1.9425]]\n",
      "Expected  th: [[-9.0], [18.0]], th0: [[2.0]]\n",
      "\n",
      "\n",
      "-----------Test Perceptron 1-----------\n",
      "Test Failed.\n",
      "Your code output  th: [[1.47], [-1.7275]], th0: [[0.985]]\n",
      "Expected  th: [[0.0], [-3.0]], th0: [[0.0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_perceptron(averaged_perceptron) # should be wrong but close to the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "\n",
    "    n = len(data_test[0])\n",
    "    cnt = 0\n",
    "    for i in range(n):\n",
    "        x = np.array([data_test[:,i]])\n",
    "        y = labels_test[:,i]\n",
    "\n",
    "        if np.sign(np.dot(x, th) + th0) == y:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Classifier 0-----------\n",
      "Passed! \n",
      "\n",
      "-----------Test Eval Classifier 1-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_classifier(eval_classifier, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    perf = 0\n",
    "    for iter in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "        perf = perf + eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    perf /= it\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval_learning_alg(eval_learning_alg, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    d = len(data)\n",
    "    data_chunk = np.array_split(data, k, axis=1)\n",
    "    lables_chunk = np.array_split(labels, k, axis=1)\n",
    "    perf = 0\n",
    "    for i in range(k):\n",
    "        data_train = np.array([[]] * d)\n",
    "        lables_train = np.array([[]])\n",
    "        for j in range(k):\n",
    "            if i != j:\n",
    "                data_train = np.concatenate((data_train, data_chunk[j]), axis=1)\n",
    "                lables_train = np.concatenate((lables_train, lables_chunk[j]), axis=1)\n",
    "        perf = perf + eval_classifier(learner, data_train, lables_train, data_chunk[i], lables_chunk[i])\n",
    "    return perf / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Test Cross-eval Learning Algo-----------\n",
      "Passed! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_xval_learning_alg(xval_learning_alg, perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7585"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8022000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6306999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_learning_alg(perceptron,           gen_flipped_lin_separable(pflip=0.1), 20, 100, 100))\n",
    "display(eval_learning_alg(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.1), 20, 100, 100))\n",
    "display(eval_learning_alg(perceptron,           gen_flipped_lin_separable(pflip=0.25), 20, 100, 100))\n",
    "display(eval_learning_alg(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.25), 20, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_training_acc(learner, data_gen, n_train, it):\n",
    "    perf = 0\n",
    "    for iter in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        perf = perf + eval_classifier(learner, data_train, labels_train, data_train, labels_train)\n",
    "    perf /= it\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8145000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8575000000000007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6935000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_training_acc(perceptron,           gen_flipped_lin_separable(pflip=0.1), 20, 100))\n",
    "display(eval_training_acc(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.1), 20, 100))\n",
    "display(eval_training_acc(perceptron,           gen_flipped_lin_separable(pflip=0.25), 20, 100))\n",
    "display(eval_training_acc(averaged_perceptron,  gen_flipped_lin_separable(pflip=0.25), 20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = np.array([[0]] * d)\n",
    "    th0 = np.array([[0]])\n",
    "\n",
    "    def decay_func(t):\n",
    "        return 0.5 - 0.4 * math.exp(-t)\n",
    "\n",
    "    for iter in range(T):\n",
    "        w = decay_func((iter + 1) / T)\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y * w\n",
    "                th = th + y * x.T * w\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "    return (th, th0)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    th = ths = np.array([[0]] * d)\n",
    "    th0 = th0s = np.array([[0]])\n",
    "    sumw = 0\n",
    "    def reverse_decay_func(t):\n",
    "        return 0.5 + 0.4 * math.exp(-t)\n",
    "        \n",
    "    for iter in range(T):\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                if hook != None:\n",
    "                    hook((th0, th))\n",
    "            \n",
    "            t = (iter * n + i + 1) / T\n",
    "            w = reverse_decay_func(t)\n",
    "            ths = ths + th * w\n",
    "            th0s = th0s + th0 * w\n",
    "            sumw += w\n",
    "    return (ths / sumw, th0s / sumw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9979999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9979999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9954999999999998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7285"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7339999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8610000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.584"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7249999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning accuracy: flip = 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5065000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5185000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.49250000000000005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"learning accuracy: flip = 0\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.1\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.1), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.25\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.25), 500, 100, 20))\n",
    "print(\"learning accuracy: flip = 0.5\")\n",
    "display(eval_learning_alg(perceptron,                   gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(averaged_perceptron,          gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(decay_perceptron,             gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))\n",
    "display(eval_learning_alg(weighted_average_perceptron,  gen_flipped_lin_separable(pflip=0.5), 500, 100, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
