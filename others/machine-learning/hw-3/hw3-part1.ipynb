{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing code_for_hw03\n",
      "Imported tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv, rv, y, positive, score\n",
      "Datasets: super_simple_separable_through_origin(), super_simple_separable(), xor(), xor_more()\n",
      "Tests for part 2: test_linear_classifier_with_features, mul, make_polynomial_feature_fun, \n",
      "                  test_with_features\n",
      "Also loaded: perceptron, one_hot_internal, test_one_hot\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from code_for_hw3_part1 import * \n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import sys\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']]\n",
      "[['-1', '8', '304', '193', '4732', '18.5', '70', '1', 'hi 1200d'], ['-1', '8', '307', '200', '4376', '15', '70', '1', 'chevy c20'], ['-1', '8', '360', '215', '4615', '14', '70', '1', 'ford f250'], ['-1', '8', '318', '210', '4382', '13.5', '70', '1', 'dodge d200'], ['-1', '8', '350', '180', '3664', '11', '73', '1', 'oldsmobile omega'], ['-1', '8', '400', '150', '4997', '14', '73', '1', 'chevrolet impala'], ['-1', '8', '429', '208', '4633', '11', '72', '1', 'mercury marquis'], ['-1', '8', '350', '160', '4456', '13.5', '72', '1', 'oldsmobile delta 88 royale'], ['-1', '8', '350', '180', '4499', '12.5', '73', '1', 'oldsmobile vista cruiser'], ['-1', '8', '383', '180', '4955', '11.5', '71', '1', 'dodge monaco (sw)']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "rawdata = None\n",
    "with open('auto-mpg.tsv', newline='') as csvfile:\n",
    "    mpgreader = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "    tsvdata = [row for row in mpgreader if len(row)]\n",
    "    rawdatatitle = tsvdata[:1]\n",
    "    rawdata = tsvdata[1:]\n",
    "print(rawdatatitle)\n",
    "print(rawdata[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_iterations = 10000\n",
    "def perceptron(data, labels, params = {}):\n",
    "    T = params.get('T', default_iterations)\n",
    "    pbar = params.get('pbar', None)\n",
    "    d = len(data)\n",
    "    n = len(data[0])\n",
    "    mistake = 0\n",
    "    th = np.array([[0]] * d)\n",
    "    th0 = np.array([[0]])\n",
    "    for iter in range(T):\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "        for i in range(n):\n",
    "            x = np.array([data[:,i]])\n",
    "            y = labels[:,i]\n",
    "            if np.sign(np.dot(x, th) + th0) != y:\n",
    "                th0 = th0 + y\n",
    "                th = th + y * x.T\n",
    "                mistake = mistake + 1\n",
    "    params['mistakes'] = mistake\n",
    "    return (th, th0)\n",
    "\n",
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test, params = {}):\n",
    "    th, th0 = learner(data_train, labels_train, params)\n",
    "    def eval(x, y):\n",
    "        return 1 if np.sign(np.dot(x, th) + th0) == y else 0\n",
    "    \n",
    "    n = len(data_train[0])\n",
    "    train_acc = np.average([eval(np.array([data_train[:,i]]), labels_train[:,i]) for i in range(n)])\n",
    "    m = len(data_test[0])    \n",
    "    test_acc = np.average([eval(np.array([data_test[:,i]]), labels_test[:,i]) for i in range(m)])\n",
    "    params['train_acc'] = train_acc\n",
    "    params['test_acc'] = test_acc\n",
    "    return 1 - train_acc\n",
    "\n",
    "\n",
    "def xval_classifier(learner, data, labels, fold, params = {}):\n",
    "    data_chunk = np.array_split(data, fold, axis=1)\n",
    "    lables_chunk = np.array_split(labels, fold, axis=1)\n",
    "    perf = 0\n",
    "    for i in range(fold):\n",
    "        data_train = np.concatenate([data_chunk[j] for j in range(fold) if i != j], axis=1)\n",
    "        lables_train = np.concatenate([lables_chunk[j] for j in range(fold) if i != j], axis=1)\n",
    "        perf = perf + eval_classifier(learner, data_train, lables_train, data_chunk[i], lables_chunk[i], params)\n",
    "    return perf / fold\n",
    "\n",
    "data = np.array([[2, 3,  4,  5]])\n",
    "labels = np.array([[1, 1, -1, -1]])\n",
    "\n",
    "eval_classifier(perceptron, data, labels, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_feature_extraction(extractor, data):\n",
    "    print(f'Evaluate {extractor.__name__}:')\n",
    "    random.shuffle(data)\n",
    "    data, labels = extractor(data)\n",
    "    # Task 1: perceptron errors\n",
    "    with tqdm(total=default_iterations * 12, file=sys.stdout) as pbar:\n",
    "        print(f'\\tParsed data dimension: {data.shape}')\n",
    "        params = {'pbar': pbar}\n",
    "        perceptron(data, labels, params)\n",
    "        print(f'\\tTask 1: mistakes = {params[\"mistakes\"]}')\n",
    "    # Task 2, 3: train and test errors\n",
    "        train_len = int(round(len(data[0]) * .9))\n",
    "        train_data, test_data = np.split(data, [train_len], axis=1)\n",
    "        train_labels, test_labels = np.split(labels, [train_len], axis=1)\n",
    "        params = {'pbar': pbar}\n",
    "        eval_classifier(perceptron, train_data, train_labels, test_data, test_labels, params)\n",
    "        print(f'\\tTask 2, 3: train accuracy = {params[\"train_acc\"]}, test accuracy = {params[\"test_acc\"]}')\n",
    "    # Task 4: cross validation\n",
    "        params = {'pbar': pbar}\n",
    "        avg_err = xval_classifier(perceptron, data, labels, 10, params)\n",
    "    print(f'\\tTask 4: Average error rate = {avg_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate simple_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d60da296f14a7b8f08fcc74ca6ceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (5, 392)\n",
      "\tTask 1: mistakes = 647398\n",
      "\tTask 2, 3: train accuracy = 0.8753541076487252, test accuracy = 0.8205128205128205\n",
      "\tTask 4: Average error rate = 0.16072302343548803\n",
      "Evaluate unstd_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebd49fe7a0c470d804fc2a8db68f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (5, 392)\n",
      "\tTask 1: mistakes = 867347\n",
      "\tTask 2, 3: train accuracy = 0.8328611898016998, test accuracy = 0.9743589743589743\n",
      "\tTask 4: Average error rate = 0.1459720254957507\n",
      "Evaluate year_one_hot_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc14afb956418f90ec8aef486f69ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (18, 392)\n",
      "\tTask 1: mistakes = 436407\n",
      "\tTask 2, 3: train accuracy = 0.8980169971671388, test accuracy = 0.7948717948717948\n",
      "\tTask 4: Average error rate = 0.11990487380891061\n",
      "Evaluate year_thermometer_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a921355a992a47cd833029d8d904e5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (18, 392)\n",
      "\tTask 1: mistakes = 392588\n",
      "\tTask 2, 3: train accuracy = 0.8810198300283286, test accuracy = 0.8974358974358975\n",
      "\tTask 4: Average error rate = 0.16697382822559875\n",
      "Evaluate simple_poly2_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f1a1991eb04e96b049cb635e3f8872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (20, 392)\n",
      "\tTask 1: mistakes = 468241\n",
      "\tTask 2, 3: train accuracy = 0.8838526912181303, test accuracy = 0.8717948717948718\n",
      "\tTask 4: Average error rate = 0.09864070950296162\n",
      "Evaluate year_one_hot_poly2_mpg_feature_extraction:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac00d5d038940959fa9bbc7a36666b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tParsed data dimension: (33, 392)\n",
      "\tTask 1: mistakes = 292370\n",
      "\tTask 2, 3: train accuracy = 0.9518413597733711, test accuracy = 0.9230769230769231\n",
      "\tTask 4: Average error rate = 0.06888037599793974\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "def standardize(row):\n",
    "    mean = np.mean(row)\n",
    "    stdev = np.std(row)\n",
    "    row = row - mean\n",
    "    row /= stdev\n",
    "    return row \n",
    "\n",
    "def simple_mpg_feature_extraction(data):\n",
    "    labels = np.array([[float(row[0]) for row in data]])\n",
    "    cylinders =     standardize(np.array([[int(row[1]) for row in data]]))\n",
    "    displacement =  standardize(np.array([[float(row[2]) for row in data]]))\n",
    "    horsepower =    standardize(np.array([[int(row[3]) for row in data]]))\n",
    "    weight =        standardize(np.array([[int(row[4]) for row in data]]))\n",
    "    acceleration =  standardize(np.array([[float(row[5]) for row in data]]))\n",
    "    # model_year = OrderedDict.fromkeys(row[6] for row in data])\t\n",
    "    # origin = dropped\n",
    "    # car_name = dropped\n",
    "    return np.concatenate((cylinders, displacement, horsepower, weight, acceleration), axis=0), labels\n",
    "\n",
    "def unstd_mpg_feature_extraction(data):\n",
    "    labels = np.array([[float(row[0]) for row in data]])\n",
    "    cylinders =     np.array([[int(row[1]) for row in data]])\n",
    "    displacement =  np.array([[float(row[2]) for row in data]])\n",
    "    horsepower =    np.array([[int(row[3]) for row in data]])\n",
    "    weight =        np.array([[int(row[4]) for row in data]])\n",
    "    acceleration =  np.array([[float(row[5]) for row in data]])\n",
    "    return np.concatenate((cylinders, displacement, horsepower, weight, acceleration), axis=0), labels\n",
    "\n",
    "def year_one_hot_mpg_feature_extraction(data):\n",
    "    cdhwa, labels = simple_mpg_feature_extraction(data)\n",
    "    year_collection = sorted(set([row[6] for row in data]))\n",
    "    model_year =  np.array([[0] * len(data) for i in range(len(year_collection))])\n",
    "    for i, row in enumerate(data):\n",
    "        model_year[year_collection.index(row[6])][i] = 1\n",
    "    return np.concatenate((cdhwa, model_year), axis=0), labels\n",
    "\n",
    "def year_thermometer_mpg_feature_extraction(data):\n",
    "    cdhwa, labels = simple_mpg_feature_extraction(data)\n",
    "    year_collection = sorted(set([row[6] for row in data]))\n",
    "    model_year =  np.array([[0] * len(data) for i in range(len(year_collection))])\n",
    "    for i, row in enumerate(data):\n",
    "        for j in range(year_collection.index(row[6]) + 1):\n",
    "            model_year[j][i] = 1\n",
    "    return np.concatenate((cdhwa, model_year), axis=0), labels\n",
    "\n",
    "\n",
    "def simple_poly2_mpg_feature_extraction(data):\n",
    "    p1basis, labels = simple_mpg_feature_extraction(data)\n",
    "    p2basis = deepcopy(p1basis)\n",
    "    for i, ri in enumerate(p1basis):\n",
    "        for j, rj in enumerate(p1basis):\n",
    "            if i <= j:\n",
    "               p2basis = np.append(p2basis, standardize([ri * rj]), axis=0)\n",
    "    return p2basis, labels\n",
    "\n",
    "def year_one_hot_poly2_mpg_feature_extraction(data):\n",
    "    p2basis, labels = simple_poly2_mpg_feature_extraction(data)\n",
    "    year_collection = sorted(set([row[6] for row in data]))\n",
    "    model_year =  np.array([[0] * len(data) for i in range(len(year_collection))])\n",
    "    for i, row in enumerate(data):\n",
    "        model_year[year_collection.index(row[6])][i] = 1\n",
    "    return np.concatenate((p2basis, model_year), axis=0), labels\n",
    "\n",
    "eval_feature_extraction(simple_mpg_feature_extraction, deepcopy(rawdata))\n",
    "eval_feature_extraction(unstd_mpg_feature_extraction, deepcopy(rawdata))\n",
    "eval_feature_extraction(year_one_hot_mpg_feature_extraction, deepcopy(rawdata))\n",
    "eval_feature_extraction(year_thermometer_mpg_feature_extraction, deepcopy(rawdata))\n",
    "eval_feature_extraction(simple_poly2_mpg_feature_extraction, deepcopy(rawdata))\n",
    "eval_feature_extraction(year_one_hot_poly2_mpg_feature_extraction, deepcopy(rawdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k):\n",
    "    return np.array([[1] if i == x - 1 else [0] for i in range(k)])\n",
    "\n",
    "one_hot(3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = np.vectorize(lambda x : one_hot(x, 6).T, signature=\"()->(n)\")\n",
    "data = encode(np.array([[2, 3,  4,  5]]))[0].T\n",
    "labels = np.array([[1, 1, -1, -1]])\n",
    "\n",
    "display(data)\n",
    "perceptron(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =   np.array([[1, 2, 3, 4, 5, 6]])\n",
    "labels = np.array([[1, 1, -1, -1, 1, 1]])\n",
    "data = encode(data)[0].T\n",
    "\n",
    "display(data)\n",
    "perceptron(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x*(x-1)//2+2*x+1 for x in [1, 10, 20, 30, 40, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_features(super_simple_separable_through_origin, 1, False, False)\n",
    "test_with_features(super_simple_separable, 1, False, False)\n",
    "test_with_features(xor, 2, False, False)\n",
    "test_with_features(xor_more, 3, False, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
