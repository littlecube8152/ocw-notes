{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 Problem Set 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 [8+8+5]\n",
    "### (a)\n",
    "We know that $A - \\mu I = X(\\Lambda - \\mu I)X^{-1}$ and the same holds for $B, Y$.  \n",
    "Let $\\mu = 2 + \\epsilon$, we know that the inverse of $M - \\mu I$ is  \n",
    "$$(A - \\mu I)^{-1} = X^{-1}\\begin{bmatrix}\\frac{1}{-1+\\epsilon} \\\\ & \\frac{1}{\\epsilon} \\\\ && \\frac 1 \\epsilon \\\\ &&& \\frac{1}{1 + \\epsilon} \\\\ &&&& \\frac{1}{2 + \\epsilon}\\end{bmatrix}X \\approx X^{-1}\\begin{bmatrix}-1 \\\\ & \\epsilon^{-1} \\\\ && \\epsilon^{-1} \\\\ &&& 1 \\\\ &&&& \\frac{1}{2}\\end{bmatrix}X$$\n",
    "Since $\\epsilon^{-1}$ is pretty large, we know that approximately, when $M = A$, $f(2 + \\epsilon, y) \\approx \\epsilon^{-1}\\|y\\|$.  \n",
    "Therefore I expect $\\alpha \\approx 10$.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "From the inverse:\n",
    "$$(B - \\mu I)^{-1} = Y^{-1}\\begin{bmatrix}\\frac{1}{-1+\\epsilon} \\\\ & \\frac{1}{\\epsilon} & -\\frac{1}{\\epsilon^2} \\\\ && \\frac 1 \\epsilon \\\\ &&& \\frac{1}{1 + \\epsilon} \\\\ &&&& \\frac{1}{2 + \\epsilon}\\end{bmatrix}Y \\approx Y^{-1}\\begin{bmatrix}-1 \\\\ & \\epsilon^{-1} & -\\epsilon^{-2} \\\\ && \\epsilon^{-1} \\\\ &&& 1 \\\\ &&&& \\frac{1}{2}\\end{bmatrix}Y$$\n",
    "Since $\\epsilon^{-2}$ is much larger than $\\epsilon^{-1}$, we know that approximately, when $M = B$, $f(2 + \\epsilon, y) \\approx \\epsilon^{-2}\\|y\\|$.  \n",
    "Therefore I expect $\\alpha \\approx 100$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(X * Λ * X ^ -1, 2.00001, y) / f(X * Λ * X ^ -1, 2.0001, y) = 9.999315068593544\n",
      "f(Y * J * Y ^ -1, 2.00001, y) / f(Y * J * Y ^ -1, 2.0001, y) = 99.99284657974198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.99284657974198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "Λ = Diagonal([1,2,2,3,4])\n",
    "J = Bidiagonal([1,2,2,3,4],[0,1,0,0],:U)\n",
    "X = randn(5,5)\n",
    "Y = randn(5,5)\n",
    "y = randn(5)\n",
    "f(M, μ, y) = norm((M - μ * I)^-1 * y)\n",
    "@show f(X * Λ * X^-1, 2.00001, y) / f(X * Λ * X^-1, 2.0001, y)\n",
    "@show f(Y * J * Y^-1, 2.00001, y) / f(Y * J * Y^-1, 2.0001, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 [10]\n",
    "Even if $A$ is **defective**, $A$ can be decomposed into  \n",
    "$$A = MJM^{-1}$$\n",
    "Where $J$ is the Jordan Form of $A$, and it contains Jordan Block which has size larger than $1$.  \n",
    "Therefore, we need to know what  \n",
    "$$\\lim_{n \\rightarrow \\infty} J^n = \\lim_{n \\rightarrow \\infty}\n",
    "\\begin{bmatrix}\n",
    "    \\lambda & 1 \\\\\n",
    "    & \\lambda & 1 \\\\\n",
    "    && \\ddots & \\ddots \\\\\n",
    "    &&& \\lambda & 1 \\\\\n",
    "    &&&& \\lambda \\\\\n",
    "\\end{bmatrix}^n$$\n",
    "is when $|\\lambda| < 1$.  \n",
    "Observe that  \n",
    "$$\\begin{bmatrix}\n",
    "    \\lambda & 1 \\\\\n",
    "    & \\lambda & 1 \\\\\n",
    "    && \\lambda \\\\\n",
    "\\end{bmatrix}^2 = \\begin{bmatrix}\n",
    "    \\lambda^2 & 2\\lambda & 1\\\\\n",
    "    & \\lambda^2 & 2\\lambda \\\\\n",
    "    && \\lambda^2 \\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "    \\lambda & 1 \\\\\n",
    "    & \\lambda & 1 \\\\\n",
    "    && \\lambda \\\\\n",
    "\\end{bmatrix}^3 = \\begin{bmatrix}\n",
    "    \\lambda^3 & 3\\lambda^2 & 3\\lambda\\\\\n",
    "    & \\lambda^3 & 3\\lambda^2 \\\\\n",
    "    && \\lambda^3 \\\\\n",
    "\\end{bmatrix}$$\n",
    "It seems that  \n",
    "$$(J^n)_{i, j} = \\binom{n}{j - i}\\lambda^{n - (j - i)}$$\n",
    "Let's prove it by Math Induction.  \n",
    "First $J^1$ satisfies the equation.  \n",
    "Second, suppose $J^k$ satisfies the equation, then $J^{k+1}$ will be  \n",
    "$$(J^{k+1})_{i, j} = \\sum_{x = 1}^{m}(J^{k})_{i, x}J_{x, j}$$\n",
    "We can consider $x = j, x = j - 1$ only.  \n",
    "$$(J^{k+1})_{i, j} = (J^{k})_{i, j}\\lambda + (J^{k})_{i, j - 1} = \\binom{k}{j - i}\\lambda^{k - (j - i) + 1} + \\binom{k}{j - i - 1}\\lambda^{k - ((j - 1) - i)} = \\binom{k + 1}{j - i}\\lambda^{k + 1 - (j - i)}$$\n",
    "By Math Induction, the formula is correct.  \n",
    "Therefore we can directly compute the limit   \n",
    "$$\\lim_{n \\rightarrow \\infty}\\binom{n}{k}|\\lambda|^{n - k} = \\lim_{n \\rightarrow \\infty} \\frac{n(n-1)\\cdots(n-k+1)}{k!}|\\lambda|^{n - k} \\leq \\lim_{n \\rightarrow \\infty} n^k|\\lambda|^{n - k} = 0$$\n",
    "So other Jordan Blocks just converge to $\\mathbf 0$ and left with the only $1$ on the diagonal. Thus these markov matrix still converges to a steady state for any column vector $x$.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 [5+5+5+2]\n",
    "### (a)\n",
    "We will obtain a good approximation of an eigenvector $q_2$ of the second largest eigenvalue $\\lambda_2$.  \n",
    "Assume that $y = c_2 q_2 + c_3 q_3 + \\cdots$, when we do the power method 1000 times, we are normalizing $c_2 \\lambda_2^{1000} q_2 + c_3 \\lambda_3^{1000} q_3 + \\cdots$, and $\\lambda_2^{1000}$ will outclass other terms, so we get $q_2$.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "Unfortunately, since we only have an approximation of $q_1$, the $c_1q_1$ will sill be significant ($c_1\\lambda_1^{1000} q_1$) when we carry the power method by 1000 times.  \n",
    "Therefore we will still get another approximation of $q_1$.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "Using \"deflation\", we will get a good approxmiation of $q_2$, the eigenvector of the eigenvalue $\\lambda_2$, since we control the $c_1q_1$ term by remove the projection everytime, so the significant one will be $c_2\\lambda_2^{1000}q_2$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       "  0.0\n",
       " -4.440892098500626e-16\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "B = randn(5,5)\n",
    "A = B'B # a random positive-definite Hermitian matrix\n",
    "\n",
    "λ = reverse(eigvals(A)) # eigenvalues in descending order\n",
    "\n",
    "# the power iteration to find q₁\n",
    "q₁ = normalize(rand(5))\n",
    "for i = 1:1000\n",
    "    q₁ = normalize(A*q₁)\n",
    "end\n",
    "\n",
    "# check that this is approximately an eigenvector of λ₁\n",
    "# — the following difference should be almost zero:\n",
    "A*q₁ - λ[1]*q₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -2.422111788308019\n",
       " -2.2285049599126405\n",
       " -7.051388849699299\n",
       "  9.437190767890224\n",
       "  0.4271830203883755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the power iteration in part (b)\n",
    "q⁽ᵇ⁾ = normalize((I - q₁*q₁')*rand(5))\n",
    "for i = 1:1000\n",
    "    q⁽ᵇ⁾ = normalize(A*q⁽ᵇ⁾)\n",
    "end\n",
    "\n",
    "# check that this is approximately an eigenvector of which λ?\n",
    "A*q⁽ᵇ⁾ - λ[2]*q⁽ᵇ⁾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -5.551115123125783e-17\n",
       "  0.0\n",
       " -1.7763568394002505e-15\n",
       " -1.7763568394002505e-15\n",
       "  2.220446049250313e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the power iteration in part (c)\n",
    "q⁽ᶜ⁾ = normalize(rand(5))\n",
    "for i = 1:1000\n",
    "    q⁽ᶜ⁾ = normalize((I - q₁*q₁')*A*q⁽ᶜ⁾)\n",
    "end\n",
    "\n",
    "# check that this is approximately an eigenvector of which λ?\n",
    "A*q⁽ᶜ⁾ - λ[2]*q⁽ᶜ⁾"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
